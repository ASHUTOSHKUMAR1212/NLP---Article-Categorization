{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9044219,"sourceType":"datasetVersion","datasetId":5452635}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\n\ndirectory_path = \"/kaggle/input/article\"\nfile_name = \"article_data.csv\"  \nfile_path = os.path.join(directory_path, file_name)\n\n# Read the CSV file\ndata = pd.read_csv(file_path)\n\n# Print the first few rows of the dataframe\nprint(data.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T09:59:53.437419Z","iopub.execute_input":"2024-07-27T09:59:53.437966Z","iopub.status.idle":"2024-07-27T09:59:53.468096Z","shell.execute_reply.started":"2024-07-27T09:59:53.437911Z","shell.execute_reply":"2024-07-27T09:59:53.466928Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"                                             Article  Category\n0  Sudan Govt rejects call to separate religion, ...         0\n1  Hassan:  #39;Abhorrent act #39; says Blair Wes...         0\n2  Sharon Says Gaza Evacuation Set for 2005 (AP) ...         0\n3  Prince Charles chastised for  quot;old fashion...         0\n4  U.S. Says N.Korea Blast Probably Not Nuclear  ...         0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Overview of the data\nprint(\"First few entries in the dataset:\")\nprint(data.head())\n\nprint(\"\\nShape of the dataset:\")\nprint(data.shape)\n\nprint(\"\\nBasic info of the dataset:\")\nprint(data.info())","metadata":{"execution":{"iopub.status.busy":"2024-07-27T09:59:55.665431Z","iopub.execute_input":"2024-07-27T09:59:55.666131Z","iopub.status.idle":"2024-07-27T09:59:55.680593Z","shell.execute_reply.started":"2024-07-27T09:59:55.666097Z","shell.execute_reply":"2024-07-27T09:59:55.679432Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"First few entries in the dataset:\n                                             Article  Category\n0  Sudan Govt rejects call to separate religion, ...         0\n1  Hassan:  #39;Abhorrent act #39; says Blair Wes...         0\n2  Sharon Says Gaza Evacuation Set for 2005 (AP) ...         0\n3  Prince Charles chastised for  quot;old fashion...         0\n4  U.S. Says N.Korea Blast Probably Not Nuclear  ...         0\n\nShape of the dataset:\n(4000, 2)\n\nBasic info of the dataset:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4000 entries, 0 to 3999\nData columns (total 2 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   Article   4000 non-null   object\n 1   Category  4000 non-null   int64 \ndtypes: int64(1), object(1)\nmemory usage: 62.6+ KB\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"# Model Building - Sentence Transformer + ML\n\n# Install the sentence-transformers library\n!pip install sentence-transformers\nimport os\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\n\n# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sentence_transformers import SentenceTransformer\n\n# Load dataset\ndata = pd.read_csv('/kaggle/input/article/article_data.csv')\n\n# Overview of the data\nprint(\"First few entries in the dataset:\")\nprint(data.head())\n\nprint(\"\\nShape of the dataset:\")\nprint(data.shape)\n\nprint(\"\\nBasic info of the dataset:\")\nprint(data.info())\n\n# Define the sentence transformer model\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\n# Encode the articles\nX = model.encode(data['Article'].tolist())\ny = data['Category']\n\n# Train-test split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Random Forest - Base model\nrf_base = RandomForestClassifier(random_state=42)\nrf_base.fit(X_train, y_train)\n\n# Predictions and evaluation\ny_pred_valid_base = rf_base.predict(X_valid)\nprint(\"Base Model - Accuracy:\", accuracy_score(y_valid, y_pred_valid_base))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred_valid_base))\nprint(\"Classification Report:\\n\", classification_report(y_valid, y_pred_valid_base))\n\n# Random Forest - Base model with class_weights\nrf_base_weighted = RandomForestClassifier(class_weight='balanced', random_state=42)\nrf_base_weighted.fit(X_train, y_train)\n\n# Predictions and evaluation\ny_pred_valid_weighted = rf_base_weighted.predict(X_valid)\nprint(\"Base Model with Class Weights - Accuracy:\", accuracy_score(y_valid, y_pred_valid_weighted))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred_valid_weighted))\nprint(\"Classification Report:\\n\", classification_report(y_valid, y_pred_valid_weighted))\n\n# Hyperparameter tuning (using GridSearchCV)\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10]\n}\n\ngrid_search = GridSearchCV(RandomForestClassifier(class_weight='balanced', random_state=42), param_grid, cv=3, n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n\n# Best model evaluation\nbest_model = grid_search.best_estimator_\ny_pred_valid_best = best_model.predict(X_valid)\nprint(\"Best Model - Accuracy:\", accuracy_score(y_valid, y_pred_valid_best))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred_valid_best))\nprint(\"Classification Report:\\n\", classification_report(y_valid, y_pred_valid_best))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T09:59:58.883543Z","iopub.execute_input":"2024-07-27T09:59:58.884173Z","iopub.status.idle":"2024-07-27T10:04:09.038548Z","shell.execute_reply.started":"2024-07-27T09:59:58.884139Z","shell.execute_reply":"2024-07-27T10:04:09.037217Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.42.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.23.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nFirst few entries in the dataset:\n                                             Article  Category\n0  Sudan Govt rejects call to separate religion, ...         0\n1  Hassan:  #39;Abhorrent act #39; says Blair Wes...         0\n2  Sharon Says Gaza Evacuation Set for 2005 (AP) ...         0\n3  Prince Charles chastised for  quot;old fashion...         0\n4  U.S. Says N.Korea Blast Probably Not Nuclear  ...         0\n\nShape of the dataset:\n(4000, 2)\n\nBasic info of the dataset:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4000 entries, 0 to 3999\nData columns (total 2 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   Article   4000 non-null   object\n 1   Category  4000 non-null   int64 \ndtypes: int64(1), object(1)\nmemory usage: 62.6+ KB\nNone\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/125 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee21911a24fd42a49ed8219e9c613135"}},"metadata":{}},{"name":"stdout","text":"Base Model - Accuracy: 0.87625\nConfusion Matrix:\n [[182   7  16   4]\n [  4 205   4   0]\n [  5   5 159  25]\n [  6   2  21 155]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.92      0.87      0.90       209\n           1       0.94      0.96      0.95       213\n           2       0.80      0.82      0.81       194\n           3       0.84      0.84      0.84       184\n\n    accuracy                           0.88       800\n   macro avg       0.87      0.87      0.87       800\nweighted avg       0.88      0.88      0.88       800\n\nBase Model with Class Weights - Accuracy: 0.88\nConfusion Matrix:\n [[180   9  10  10]\n [  5 206   1   1]\n [  5   3 165  21]\n [  6   2  23 153]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.92      0.86      0.89       209\n           1       0.94      0.97      0.95       213\n           2       0.83      0.85      0.84       194\n           3       0.83      0.83      0.83       184\n\n    accuracy                           0.88       800\n   macro avg       0.88      0.88      0.88       800\nweighted avg       0.88      0.88      0.88       800\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"Best Model - Accuracy: 0.8825\nConfusion Matrix:\n [[180  10  12   7]\n [  2 206   2   3]\n [  5   3 164  22]\n [  7   3  18 156]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.93      0.86      0.89       209\n           1       0.93      0.97      0.95       213\n           2       0.84      0.85      0.84       194\n           3       0.83      0.85      0.84       184\n\n    accuracy                           0.88       800\n   macro avg       0.88      0.88      0.88       800\nweighted avg       0.88      0.88      0.88       800\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Model Building - Transformer\n\nfrom datasets import Dataset\nimport pandas as pd\n\n# Load dataset\ndata = pd.read_csv('/kaggle/input/article/article_data.csv')\n\n# Convert DataFrame to Hugging Face Dataset\ndataset = Dataset.from_pandas(data)\n\n# Map label column to integer\ndataset = dataset.map(lambda examples: {'labels': examples['Category']}, batched=True)\n\n# Split dataset into train and validation\ndataset = dataset.train_test_split(test_size=0.2, seed=42)\ntrain_dataset = dataset['train']\nvalid_dataset = dataset['test']\n\n# Define a function to preprocess the data with prompt\ndef preprocess_function(examples):\n    prompts = [\"Classify the following article: \" + text for text in examples['Article']]\n    return tokenizer(prompts, padding='max_length', truncation=True, return_tensors='pt')\n\n# Preprocess datasets\ntrain_dataset = train_dataset.map(preprocess_function, batched=True)\nvalid_dataset = valid_dataset.map(preprocess_function, batched=True)\n\n# Set format for PyTorch\ntrain_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\nvalid_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T10:04:19.900854Z","iopub.execute_input":"2024-07-27T10:04:19.901174Z","iopub.status.idle":"2024-07-27T10:04:30.639615Z","shell.execute_reply.started":"2024-07-27T10:04:19.901146Z","shell.execute_reply":"2024-07-27T10:04:30.638817Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"608820a0f9624ec3b1ee2f3b4e8a3949"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02abe39042e24e06a2bdac5e1731987f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9e4f054f6884c8e9e1c4ebbc245491e"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, pipeline\nimport os\n\n# Ensure W&B is not initialized\nos.environ['WANDB_DISABLED'] = 'true'\n\n# Load tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(data['Category'].unique()))\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',          \n    num_train_epochs=3,              \n    per_device_train_batch_size=8,   # batch size for training\n    per_device_eval_batch_size=8,    \n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               \n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=10,\n    evaluation_strategy='steps',    \n    save_strategy='steps',          \n    save_steps=500,                  \n    eval_steps=500,                 \n    report_to=None,                 \n    load_best_model_at_end=True,    \n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,                         \n    args=training_args,                  \n    train_dataset=train_dataset,         \n    eval_dataset=valid_dataset,          \n)\n\n# Train the model\ntrainer.train()\n\n# Evaluate the model\nresults = trainer.evaluate()\n\nprint(\"Evaluation Results:\")\nprint(f\"Loss: {results['eval_loss']}\")\nprint(f\"Metrics: {results}\")\n\n# Example prediction\n# Create a classification pipeline\nclassifier = pipeline('text-classification', model=model, tokenizer=tokenizer)\n\n# Example prediction\nexample_text = \"Example text for classification.\"\nprediction = classifier(example_text)\n\nprint(f\"Prediction: {prediction}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T10:04:30.641480Z","iopub.execute_input":"2024-07-27T10:04:30.641791Z","iopub.status.idle":"2024-07-27T10:13:30.957792Z","shell.execute_reply.started":"2024-07-27T10:04:30.641763Z","shell.execute_reply":"2024-07-27T10:13:30.956755Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [600/600 08:44, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.187300</td>\n      <td>0.419737</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 00:13]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"name":"stdout","text":"Evaluation Results:\nLoss: 0.4197366237640381\nMetrics: {'eval_loss': 0.4197366237640381, 'eval_runtime': 13.7389, 'eval_samples_per_second': 58.229, 'eval_steps_per_second': 3.639, 'epoch': 3.0}\nPrediction: [{'label': 'LABEL_3', 'score': 0.956001341342926}]\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n\n# Load DistilBERT tokenizer and model\ntokenizer_distilbert = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nmodel_distilbert = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(data['Category'].unique()))\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results_distilbert',\n    num_train_epochs=3,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs_distilbert',\n    logging_steps=10,\n    evaluation_strategy='steps',\n    save_strategy='steps',\n    save_steps=500,\n    eval_steps=500,\n    report_to=None,\n    load_best_model_at_end=True,\n)\n\n# Initialize Trainer for DistilBERT\ntrainer_distilbert = Trainer(\n    model=model_distilbert,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n)\n\n# Train the DistilBERT model\ntrainer_distilbert.train()\n\n# Evaluate the DistilBERT model\nresults_distilbert = trainer_distilbert.evaluate()\n\nprint(\"DistilBERT Evaluation Results:\")\nprint(f\"Loss: {results_distilbert['eval_loss']}\")\nprint(f\"Metrics: {results_distilbert}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T10:16:50.258043Z","iopub.execute_input":"2024-07-27T10:16:50.259100Z","iopub.status.idle":"2024-07-27T10:21:27.154299Z","shell.execute_reply.started":"2024-07-27T10:16:50.259060Z","shell.execute_reply":"2024-07-27T10:21:27.153254Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20a7c6a4b73c418b909d8d59015a5d7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0c516f42a1943b59b718e7ce863a67b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9fd5f99a5fe43c2916e5524f9f1c22c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af9410355dac4043b6519c66f569bbb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7d338cac9154d92bb1297f8c2414849"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [600/600 04:25, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.338400</td>\n      <td>0.435590</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 00:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"DistilBERT Evaluation Results:\nLoss: 0.43558964133262634\nMetrics: {'eval_loss': 0.43558964133262634, 'eval_runtime': 7.2964, 'eval_samples_per_second': 109.644, 'eval_steps_per_second': 6.853, 'epoch': 3.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Apply the Best Model\n\nfrom transformers import pipeline\nfrom datasets import Dataset\nimport pandas as pd\n\n# Load test data\ntest_data = pd.read_csv('/kaggle/input/article/article_data.csv')\n\n# Convert test data to Hugging Face Dataset\ntest_dataset = Dataset.from_pandas(test_data)\n\n# Preprocess test dataset\ndef preprocess_function(examples):\n    return tokenizer(examples['Article'], padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n\ntest_dataset = test_dataset.map(preprocess_function, batched=True)\ntest_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n\n# Define a function to predict with the best model\ndef predict(texts):\n    # Use the best tokenizer for prediction\n    predictions = classifier(texts)\n    return predictions\n\n# Create a classification pipeline with the best model\nclassifier = pipeline('text-classification', model=best_model, tokenizer=best_tokenizer, device=0)  # Use GPU if available\n\n# Apply the best model to test data\ntest_texts = test_data['Article'].tolist()\ntest_predictions = predict(test_texts)\n\n# Print example predictions\nfor i, pred in enumerate(test_predictions[:5]):\n    print(f\"Example {i}: {pred}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T10:25:06.957380Z","iopub.execute_input":"2024-07-27T10:25:06.958196Z","iopub.status.idle":"2024-07-27T10:26:01.129799Z","shell.execute_reply.started":"2024-07-27T10:25:06.958158Z","shell.execute_reply":"2024-07-27T10:26:01.128680Z"},"trusted":true},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa1c7addaa274a8f8204d9c0ef0bc63d"}},"metadata":{}},{"name":"stdout","text":"Example 0: {'label': 'LABEL_0', 'score': 0.993241548538208}\nExample 1: {'label': 'LABEL_0', 'score': 0.9936322569847107}\nExample 2: {'label': 'LABEL_0', 'score': 0.9935747981071472}\nExample 3: {'label': 'LABEL_0', 'score': 0.9807139039039612}\nExample 4: {'label': 'LABEL_0', 'score': 0.9931232333183289}\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Reload data\ndata = pd.read_csv('/kaggle/input/article/article_data.csv')\n\n# Split dataset into train and validation again\ndataset = Dataset.from_pandas(data)\ndataset = dataset.train_test_split(test_size=0.2, seed=42)\ntrain_data = dataset['train'].to_pandas()\nvalid_data = dataset['test'].to_pandas()\n\n# Check class distribution in the dataset\nprint(\"Training Data Class Distribution:\")\nprint(train_data['Category'].value_counts())\n\nprint(\"Validation Data Class Distribution:\")\nprint(valid_data['Category'].value_counts())\n\nprint(\"Test Data Class Distribution:\")\nprint(test_data['Category'].value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T10:27:19.660979Z","iopub.execute_input":"2024-07-27T10:27:19.661668Z","iopub.status.idle":"2024-07-27T10:27:19.727535Z","shell.execute_reply.started":"2024-07-27T10:27:19.661633Z","shell.execute_reply":"2024-07-27T10:27:19.726454Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Training Data Class Distribution:\nCategory\n0    814\n3    803\n1    800\n2    783\nName: count, dtype: int64\nValidation Data Class Distribution:\nCategory\n2    217\n1    200\n3    197\n0    186\nName: count, dtype: int64\nTest Data Class Distribution:\nCategory\n0    1000\n1    1000\n2    1000\n3    1000\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Ensure test_data is loaded\ntest_data = pd.read_csv('/kaggle/input/article/article_data.csv')\n\n# Check predictions\ntest_texts = test_data['Article'].tolist()  \ntest_predictions = predict(test_texts)\n\n# Convert predictions to DataFrame\npredictions_df = pd.DataFrame(test_predictions)\n\n# Print first few predictions\nprint(predictions_df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-07-27T10:28:03.485893Z","iopub.execute_input":"2024-07-27T10:28:03.486284Z","iopub.status.idle":"2024-07-27T10:28:47.850494Z","shell.execute_reply.started":"2024-07-27T10:28:03.486251Z","shell.execute_reply":"2024-07-27T10:28:47.849430Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"     label     score\n0  LABEL_0  0.993242\n1  LABEL_0  0.993632\n2  LABEL_0  0.993575\n3  LABEL_0  0.980714\n4  LABEL_0  0.993123\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Actionable Insights and Recommendations\n\n## Model Performance:\n\n    Base Model Accuracy: Achieved an accuracy of 87.63%, demonstrating strong performance but leaving room for improvement.\n    Base Model with Class Weights Accuracy: Slightly improved accuracy at 88%, indicating that class weighting helped balance the performance across classes.\n    Best Model Accuracy: Reached an accuracy of 88.25%, confirming that tuning or additional optimizations have positively impacted performance.\n    Loss Metrics: The training and validation losses for the best model are 0.1873 and 0.4197 respectively, reflecting good model fit but suggesting there is still some room for reducing overfitting.\n\n## Classification Report:\n\n    Precision and Recall: The model performs well across most classes, with particularly high precision and recall for classes 0 and 1. However, class 2 and class 3 have slightly lower scores, indicating room for improvement.\n    F1 Scores: The F1 scores are consistently high, showing a good balance between precision and recall, though class 2 and class 3 could benefit from additional tuning.\n\n## Class Distribution:\n\n    Training Data: Balanced across all categories, ensuring the model is trained on a representative sample.\n    Validation Data: Slightly imbalanced but still fairly balanced; validation metrics are reflective of training data performance.\n    Test Data: Perfectly balanced, providing a fair assessment of model performance across all classes.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}